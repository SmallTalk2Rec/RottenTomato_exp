{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/envs/rec-modeling-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/shin/.cache/kagglehub/datasets/andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews/versions/4\n",
      "(143258, 16)\n",
      "(1444963, 11)\n"
     ]
    }
   ],
   "source": [
    "# 다운로드 받는 코드\n",
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews\")\n",
    "path = path.replace('\\\\', '/')\n",
    "\n",
    "review_df = pd.read_csv(os.path.join(path, os.listdir(path)[0]))\n",
    "movie_df = pd.read_csv(os.path.join(path, os.listdir(path)[1]))\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(movie_df.shape)\n",
    "print(review_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143258 entries, 0 to 143257\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    143258 non-null  object \n",
      " 1   title                 142891 non-null  object \n",
      " 2   audienceScore         73248 non-null   float64\n",
      " 3   tomatoMeter           33877 non-null   float64\n",
      " 4   rating                13991 non-null   object \n",
      " 5   ratingContents        13991 non-null   object \n",
      " 6   releaseDateTheaters   30773 non-null   object \n",
      " 7   releaseDateStreaming  79420 non-null   object \n",
      " 8   runtimeMinutes        129431 non-null  float64\n",
      " 9   genre                 132175 non-null  object \n",
      " 10  originalLanguage      129400 non-null  object \n",
      " 11  director              139041 non-null  object \n",
      " 12  writer                90116 non-null   object \n",
      " 13  boxOffice             14743 non-null   object \n",
      " 14  distributor           23001 non-null   object \n",
      " 15  soundMix              15917 non-null   object \n",
      "dtypes: float64(3), object(13)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2913,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df[\"genre\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>originalScore</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>scoreSentiment</th>\n",
       "      <th>reviewUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beavers</td>\n",
       "      <td>1145982</td>\n",
       "      <td>2003-05-23</td>\n",
       "      <td>Ivan M. Lincoln</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5/4</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Deseret News (Salt Lake City)</td>\n",
       "      <td>Timed to be just long enough for most youngste...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.deseretnews.com/article/700003233/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood_mask</td>\n",
       "      <td>1636744</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>The Foywonder</td>\n",
       "      <td>False</td>\n",
       "      <td>1/5</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Dread Central</td>\n",
       "      <td>It doesn't matter if a movie costs 300 million...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>http://www.dreadcentral.com/index.php?name=Rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_hunter_shinjuku_private_eyes</td>\n",
       "      <td>2590987</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>Reuben Baron</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>CBR</td>\n",
       "      <td>The choreography is so precise and lifelike at...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.cbr.com/city-hunter-shinjuku-priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_hunter_shinjuku_private_eyes</td>\n",
       "      <td>2558908</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>Matt Schley</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5/5</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Japan Times</td>\n",
       "      <td>The film's out-of-touch attempts at humor may ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>https://www.japantimes.co.jp/culture/2019/02/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dangerous_men_2015</td>\n",
       "      <td>2504681</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>Pat Padua</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>DCist</td>\n",
       "      <td>Its clumsy determination is endearing and some...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://dcist.com/2015/11/out_of_frame_dangerou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  reviewId creationDate       criticName  \\\n",
       "0                            beavers   1145982   2003-05-23  Ivan M. Lincoln   \n",
       "1                         blood_mask   1636744   2007-06-02    The Foywonder   \n",
       "2  city_hunter_shinjuku_private_eyes   2590987   2019-05-28     Reuben Baron   \n",
       "3  city_hunter_shinjuku_private_eyes   2558908   2019-02-14      Matt Schley   \n",
       "4                 dangerous_men_2015   2504681   2018-08-29        Pat Padua   \n",
       "\n",
       "   isTopCritic originalScore reviewState                 publicatioName  \\\n",
       "0        False         3.5/4       fresh  Deseret News (Salt Lake City)   \n",
       "1        False           1/5      rotten                  Dread Central   \n",
       "2        False           NaN       fresh                            CBR   \n",
       "3        False         2.5/5      rotten                    Japan Times   \n",
       "4        False           NaN       fresh                          DCist   \n",
       "\n",
       "                                          reviewText scoreSentiment  \\\n",
       "0  Timed to be just long enough for most youngste...       POSITIVE   \n",
       "1  It doesn't matter if a movie costs 300 million...       NEGATIVE   \n",
       "2  The choreography is so precise and lifelike at...       POSITIVE   \n",
       "3  The film's out-of-touch attempts at humor may ...       NEGATIVE   \n",
       "4  Its clumsy determination is endearing and some...       POSITIVE   \n",
       "\n",
       "                                           reviewUrl  \n",
       "0  http://www.deseretnews.com/article/700003233/B...  \n",
       "1  http://www.dreadcentral.com/index.php?name=Rev...  \n",
       "2  https://www.cbr.com/city-hunter-shinjuku-priva...  \n",
       "3  https://www.japantimes.co.jp/culture/2019/02/0...  \n",
       "4  http://dcist.com/2015/11/out_of_frame_dangerou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data train & test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop_duplicates(inplace=True)\n",
    "review_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(56.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df[\"id\"].value_counts().quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_movie_ids = review_df['id'].value_counts()[review_df['id'].value_counts()>=56].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['joker_2019', 'once_upon_a_time_in_hollywood', 'avengers_endgame',\n",
       "       'captain_marvel', 'a_star_is_born_2018', 'black_panther_2018',\n",
       "       'star_wars_the_rise_of_skywalker', 'the_batman', 'dune_2021',\n",
       "       'avengers_infinity_war',\n",
       "       ...\n",
       "       'i_am_trying_to_break_your_heart', 'stolen_summer',\n",
       "       'friends_the_reunion', 'clara_sola', 'stand_by_me_1986', 'devils_due',\n",
       "       '1090089-jack_frost', 'cookies_fortune', 'welcome_to_new_york_2015',\n",
       "       'lux_aeterna'],\n",
       "      dtype='object', name='id', length=6963)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_review_df = review_df[review_df['id'].isin(selected_movie_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_review_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>originalScore</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>scoreSentiment</th>\n",
       "      <th>reviewUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2763233</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Richard Crouse</td>\n",
       "      <td>False</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Richard Crouse</td>\n",
       "      <td>A school comedy so predictable the screenwrite...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.richardcrouse.ca/the-duff-3-stars-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2692661</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>Andrew Galdi</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Movie Bitches</td>\n",
       "      <td>It was good acting and good writing.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.youtube.com/watch?v=8KeoWwUtXVQ&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2679627</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>Avaryl Halley</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Movie Bitches</td>\n",
       "      <td>Oh dear, am I the Duff?</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.youtube.com/watch?v=8KeoWwUtXVQ&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2615809</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>Udita Jhunjhunwala</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>While director Ari Sandel's adaptation is devo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.livemint.com/Leisure/3wDs58QVt0Mtm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2586271</td>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>Olivia Luder</td>\n",
       "      <td>True</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>One Room With A View</td>\n",
       "      <td>Not clever enough to be genre-defining in its ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://oneroomwithaview.com/2015/03/06/duff-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  reviewId creationDate          criticName  isTopCritic  \\\n",
       "0  the_duff   2763233   2021-02-02      Richard Crouse        False   \n",
       "1  the_duff   2692661   2020-05-27        Andrew Galdi        False   \n",
       "2  the_duff   2679627   2020-03-26       Avaryl Halley        False   \n",
       "3  the_duff   2615809   2019-08-15  Udita Jhunjhunwala         True   \n",
       "4  the_duff   2586271   2019-05-14        Olivia Luder         True   \n",
       "\n",
       "  originalScore reviewState        publicatioName  \\\n",
       "0           3/5       fresh        Richard Crouse   \n",
       "1           NaN       fresh         Movie Bitches   \n",
       "2           NaN       fresh         Movie Bitches   \n",
       "3           NaN       fresh              Livemint   \n",
       "4           3/5       fresh  One Room With A View   \n",
       "\n",
       "                                          reviewText scoreSentiment  \\\n",
       "0  A school comedy so predictable the screenwrite...       POSITIVE   \n",
       "1               It was good acting and good writing.       POSITIVE   \n",
       "2                            Oh dear, am I the Duff?       POSITIVE   \n",
       "3  While director Ari Sandel's adaptation is devo...       POSITIVE   \n",
       "4  Not clever enough to be genre-defining in its ...       POSITIVE   \n",
       "\n",
       "                                           reviewUrl  \n",
       "0  http://www.richardcrouse.ca/the-duff-3-stars-a...  \n",
       "1  https://www.youtube.com/watch?v=8KeoWwUtXVQ&li...  \n",
       "2  https://www.youtube.com/watch?v=8KeoWwUtXVQ&li...  \n",
       "3  https://www.livemint.com/Leisure/3wDs58QVt0Mtm...  \n",
       "4  https://oneroomwithaview.com/2015/03/06/duff-r...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_reviewer_names = selected_review_df['criticName'].value_counts()[selected_review_df['criticName'].value_counts()>=4].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Frank Swietek', 'Roger Moore', 'Brian Orndorf', 'Jeffrey M. Anderson',\n",
       "       'Rich Cline', 'Nell Minow', 'Laura Clifford', 'James Berardinelli',\n",
       "       'Dennis Schwartz', 'David Nusair',\n",
       "       ...\n",
       "       'Rob Mackie', 'Erick Massoto', 'Sarah Raskin', 'Brian Grubb',\n",
       "       'Sierra Bilton', 'D.W. Mault', 'Russell Holly', 'Adam Bernstein',\n",
       "       'Florence Epstein', 'Jason Rhode'],\n",
       "      dtype='object', name='criticName', length=6093)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_reviewer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>originalScore</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>scoreSentiment</th>\n",
       "      <th>reviewUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2763233</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Richard Crouse</td>\n",
       "      <td>False</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Richard Crouse</td>\n",
       "      <td>A school comedy so predictable the screenwrite...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.richardcrouse.ca/the-duff-3-stars-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2692661</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>Andrew Galdi</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Movie Bitches</td>\n",
       "      <td>It was good acting and good writing.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.youtube.com/watch?v=8KeoWwUtXVQ&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2679627</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>Avaryl Halley</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Movie Bitches</td>\n",
       "      <td>Oh dear, am I the Duff?</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.youtube.com/watch?v=8KeoWwUtXVQ&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2615809</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>Udita Jhunjhunwala</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>While director Ari Sandel's adaptation is devo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://www.livemint.com/Leisure/3wDs58QVt0Mtm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_duff</td>\n",
       "      <td>2586271</td>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>Olivia Luder</td>\n",
       "      <td>True</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>One Room With A View</td>\n",
       "      <td>Not clever enough to be genre-defining in its ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>https://oneroomwithaview.com/2015/03/06/duff-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  reviewId creationDate          criticName  isTopCritic  \\\n",
       "0  the_duff   2763233   2021-02-02      Richard Crouse        False   \n",
       "1  the_duff   2692661   2020-05-27        Andrew Galdi        False   \n",
       "2  the_duff   2679627   2020-03-26       Avaryl Halley        False   \n",
       "3  the_duff   2615809   2019-08-15  Udita Jhunjhunwala         True   \n",
       "4  the_duff   2586271   2019-05-14        Olivia Luder         True   \n",
       "\n",
       "  originalScore reviewState        publicatioName  \\\n",
       "0           3/5       fresh        Richard Crouse   \n",
       "1           NaN       fresh         Movie Bitches   \n",
       "2           NaN       fresh         Movie Bitches   \n",
       "3           NaN       fresh              Livemint   \n",
       "4           3/5       fresh  One Room With A View   \n",
       "\n",
       "                                          reviewText scoreSentiment  \\\n",
       "0  A school comedy so predictable the screenwrite...       POSITIVE   \n",
       "1               It was good acting and good writing.       POSITIVE   \n",
       "2                            Oh dear, am I the Duff?       POSITIVE   \n",
       "3  While director Ari Sandel's adaptation is devo...       POSITIVE   \n",
       "4  Not clever enough to be genre-defining in its ...       POSITIVE   \n",
       "\n",
       "                                           reviewUrl  \n",
       "0  http://www.richardcrouse.ca/the-duff-3-stars-a...  \n",
       "1  https://www.youtube.com/watch?v=8KeoWwUtXVQ&li...  \n",
       "2  https://www.youtube.com/watch?v=8KeoWwUtXVQ&li...  \n",
       "3  https://www.livemint.com/Leisure/3wDs58QVt0Mtm...  \n",
       "4  https://oneroomwithaview.com/2015/03/06/duff-r...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_review_df = selected_review_df[selected_review_df['criticName'].isin(selected_reviewer_names)]\n",
    "selected_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917415, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_review_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'reviewId', 'creationDate', 'criticName', 'isTopCritic',\n",
       "       'originalScore', 'reviewState', 'publicatioName', 'reviewText',\n",
       "       'scoreSentiment', 'reviewUrl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_review_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(selected_review_df.drop('reviewState', axis=1), selected_review_df['reviewState'], stratify=selected_review_df.criticName, test_size=0.1)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, stratify=X_train.criticName, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF-NCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "user_encoder.fit(X_train[\"criticName\"])\n",
    "item_encoder.fit(X_train[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, X, Y, user_encoder, item_encoder):\n",
    "        self.user = torch.LongTensor(user_encoder.transform(X[\"criticName\"]))\n",
    "        self.item = torch.LongTensor(item_encoder.transform(X[\"id\"]))\n",
    "        \n",
    "        self.Y = torch.FloatTensor([1 if y == \"fresh\" else 0 for y in Y.to_list()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user[idx], self.item[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    " \n",
    " \n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, embedding_dim=32, hidden_units=[256, 128, 64]):\n",
    "        super(NCF, self).__init__()\n",
    "        self.embed_user = nn.Embedding(user_num, embedding_dim)\n",
    "        self.embed_item = nn.Embedding(item_num, embedding_dim)\n",
    "\n",
    "        MLP_layers = []\n",
    "        input_size = embedding_dim * 2\n",
    "        for hidden_unit in hidden_units:\n",
    "            MLP_layers.append(nn.Linear(input_size, hidden_unit))\n",
    "            MLP_layers.append(nn.ReLU())\n",
    "            input_size = hidden_unit\n",
    "        self.MLP_layers = nn.Sequential(*MLP_layers)\n",
    "\n",
    "        self.predict_layer = nn.Linear(input_size, 1)\n",
    " \n",
    "    def forward(self, user, item):\n",
    "        embed_user = self.embed_user(user)\n",
    "        embed_item = self.embed_item(item)\n",
    "        interaction = torch.cat((embed_user, embed_item), -1)\n",
    "        output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        prediction = self.predict_layer(output_MLP)\n",
    "        return prediction.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01: 100%|██████████| 2419/2419 [00:03<00:00, 630.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01, TRAIN LOSS: 0.5572, TRAIN ACC: 0.72%, VAL LOSS: 0.4970, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02: 100%|██████████| 2419/2419 [00:03<00:00, 669.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02, TRAIN LOSS: 0.4709, TRAIN ACC: 0.78%, VAL LOSS: 0.4716, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03: 100%|██████████| 2419/2419 [00:03<00:00, 678.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03, TRAIN LOSS: 0.4523, TRAIN ACC: 0.78%, VAL LOSS: 0.4665, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04: 100%|██████████| 2419/2419 [00:03<00:00, 633.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04, TRAIN LOSS: 0.4430, TRAIN ACC: 0.79%, VAL LOSS: 0.4641, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 05: 100%|██████████| 2419/2419 [00:03<00:00, 662.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05, TRAIN LOSS: 0.4361, TRAIN ACC: 0.79%, VAL LOSS: 0.4639, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 06: 100%|██████████| 2419/2419 [00:03<00:00, 634.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06, TRAIN LOSS: 0.4296, TRAIN ACC: 0.80%, VAL LOSS: 0.4653, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 07: 100%|██████████| 2419/2419 [00:03<00:00, 672.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07, TRAIN LOSS: 0.4228, TRAIN ACC: 0.80%, VAL LOSS: 0.4721, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 08: 100%|██████████| 2419/2419 [00:03<00:00, 674.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08, TRAIN LOSS: 0.4155, TRAIN ACC: 0.80%, VAL LOSS: 0.4759, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 09: 100%|██████████| 2419/2419 [00:03<00:00, 667.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09, TRAIN LOSS: 0.4072, TRAIN ACC: 0.81%, VAL LOSS: 0.4801, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 10: 100%|██████████| 2419/2419 [00:03<00:00, 678.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10, TRAIN LOSS: 0.3986, TRAIN ACC: 0.81%, VAL LOSS: 0.4885, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 11: 100%|██████████| 2419/2419 [00:03<00:00, 667.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11, TRAIN LOSS: 0.3890, TRAIN ACC: 0.82%, VAL LOSS: 0.5029, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 12: 100%|██████████| 2419/2419 [00:03<00:00, 673.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12, TRAIN LOSS: 0.3790, TRAIN ACC: 0.82%, VAL LOSS: 0.5088, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 13: 100%|██████████| 2419/2419 [00:03<00:00, 671.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13, TRAIN LOSS: 0.3684, TRAIN ACC: 0.83%, VAL LOSS: 0.5286, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 14: 100%|██████████| 2419/2419 [00:03<00:00, 671.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14, TRAIN LOSS: 0.3575, TRAIN ACC: 0.83%, VAL LOSS: 0.5447, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 15: 100%|██████████| 2419/2419 [00:03<00:00, 673.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, TRAIN LOSS: 0.3469, TRAIN ACC: 0.84%, VAL LOSS: 0.5602, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 16: 100%|██████████| 2419/2419 [00:03<00:00, 680.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16, TRAIN LOSS: 0.3360, TRAIN ACC: 0.84%, VAL LOSS: 0.5882, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 17: 100%|██████████| 2419/2419 [00:03<00:00, 670.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17, TRAIN LOSS: 0.3250, TRAIN ACC: 0.85%, VAL LOSS: 0.6080, VAL ACC: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 18: 100%|██████████| 2419/2419 [00:03<00:00, 672.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18, TRAIN LOSS: 0.3143, TRAIN ACC: 0.86%, VAL LOSS: 0.6299, VAL ACC: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 19: 100%|██████████| 2419/2419 [00:03<00:00, 671.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19, TRAIN LOSS: 0.3038, TRAIN ACC: 0.86%, VAL LOSS: 0.6558, VAL ACC: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 20: 100%|██████████| 2419/2419 [00:03<00:00, 671.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, TRAIN LOSS: 0.2939, TRAIN ACC: 0.87%, VAL LOSS: 0.6788, VAL ACC: 0.74%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = ReviewDataset(X_train, Y_train, user_encoder, item_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = ReviewDataset(X_val, Y_val, user_encoder, item_encoder)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = NCF(user_num=len(user_encoder.classes_), item_num=len(item_encoder.classes_)).to(device)\n",
    "fn_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def fn_acc(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    시그모이드를 적용한 예측값과 실제값으로 정확도를 계산합니다.\n",
    "    \"\"\"\n",
    "    predictions = (torch.sigmoid(y_pred) >= 0.5).float()\n",
    "    correct = (predictions == y_true).float().sum()\n",
    "    return correct / len(y_true)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total_train_samples = 0\n",
    "    for user, item, y in tqdm(train_loader, desc=f\"EPOCH: {epoch+1:02d}\"):\n",
    "        user, item, y = user.to(device), item.to(device), y.to(device)\n",
    "        y_hat = model(user, item)\n",
    "        loss = fn_loss(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = y.size(0)\n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_acc += fn_acc(y_hat, y) * batch_size\n",
    "        total_train_samples += batch_size\n",
    "        \n",
    "    train_loss /= total_train_samples\n",
    "    train_acc = (train_acc / total_train_samples)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, y in val_loader:\n",
    "            user, item, y = user.to(device), item.to(device), y.to(device)\n",
    "            y_hat = model(user, item)\n",
    "            loss = fn_loss(y_hat, y)\n",
    "            \n",
    "            batch_size = y.size(0)\n",
    "            val_loss += loss.item() * batch_size\n",
    "            val_acc += fn_acc(y_hat, y) * batch_size\n",
    "            total_val_samples += batch_size\n",
    "        \n",
    "    val_loss /= total_val_samples\n",
    "    val_acc = (val_acc / total_val_samples)\n",
    "    \n",
    "    print(f\"EPOCH: {epoch+1:02d}, \"\n",
    "          f\"TRAIN LOSS: {train_loss:.4f}, TRAIN ACC: {train_acc:.2f}%, \"\n",
    "          f\"VAL LOSS: {val_loss:.4f}, VAL ACC: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 생성 중...\n",
      "테스트 데이터 수: 91742\n",
      "모델 평가 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 359/359 [00:00<00:00, 771.12batch/s, loss=0.4739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "모델 평가 결과\n",
      "==================================================\n",
      "Loss: 0.4868\n",
      "Accuracy: 0.7699\n",
      "Precision: 0.7972\n",
      "Recall: 0.8770\n",
      "F1 Score: 0.8352\n",
      "AUC-ROC: 0.8274\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    모델을 평가하고 다양한 평가 지표를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    model: 학습된 모델\n",
    "    test_loader: 테스트 데이터 로더\n",
    "    device: 연산 장치 (CPU/GPU)\n",
    "    \n",
    "    Returns:\n",
    "    dict: 다양한 평가 지표를 포함한 딕셔너리\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 예측값과 실제값을 저장할 리스트\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_targets = []\n",
    "    total_loss = 0\n",
    "    fn_loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # tqdm으로 진행상황 표시\n",
    "    test_progress = tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, y in test_progress:\n",
    "            # 데이터를 device로 이동\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            y_hat = model(user, item)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = fn_loss(y_hat, y)\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            \n",
    "            # 시그모이드 함수를 통한 확률값 계산\n",
    "            probabilities = torch.sigmoid(y_hat)\n",
    "            \n",
    "            # 예측 클래스 결정 (0.5를 임계값으로 사용)\n",
    "            predictions = (probabilities >= 0.5).float()\n",
    "            \n",
    "            # CPU로 이동하고 numpy 배열로 변환\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            \n",
    "            # 진행바 업데이트\n",
    "            test_progress.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # numpy 배열로 변환\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # 평균 손실 계산\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # 각종 평가 지표 계산\n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy_score(all_targets, all_predictions),\n",
    "        'precision': precision_score(all_targets, all_predictions),\n",
    "        'recall': recall_score(all_targets, all_predictions),\n",
    "        'f1': f1_score(all_targets, all_predictions),\n",
    "        'auc_roc': roc_auc_score(all_targets, all_probabilities)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 평가 실행\n",
    "def print_evaluation_results(metrics):\n",
    "    \"\"\"\n",
    "    평가 결과를 보기 좋게 출력합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"모델 평가 결과\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# 테스트 데이터셋 생성 및 평가 실행\n",
    "def evaluate_test_set(X_test, Y_test, model, user_encoder, item_encoder, batch_size=256):\n",
    "    \"\"\"\n",
    "    테스트 데이터셋을 생성하고 모델을 평가합니다.\n",
    "    \"\"\"\n",
    "    print(\"테스트 데이터셋 생성 중...\")\n",
    "    test_dataset = ReviewDataset(X_test, Y_test, user_encoder, item_encoder)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False  # 테스트 시에는 모든 샘플을 평가\n",
    "    )\n",
    "    \n",
    "    print(f\"테스트 데이터 수: {len(test_dataset)}\")\n",
    "    print(\"모델 평가 중...\")\n",
    "    \n",
    "    # 평가 실행\n",
    "    device = next(model.parameters()).device  # 모델이 있는 디바이스 확인\n",
    "    metrics = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print_evaluation_results(metrics)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_test_set(\n",
    "    X_test=X_test,\n",
    "    Y_test=Y_test,\n",
    "    model=model,\n",
    "    user_encoder=user_encoder,\n",
    "    item_encoder=item_encoder,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF-NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    " \n",
    " \n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, factor_num=32, num_layers=3):\n",
    "        super(NCF, self).__init__()\n",
    "        self.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
    "        self.embed_user_MLP = nn.Embedding(\n",
    "\t\t\t\tuser_num, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.embed_item_MLP = nn.Embedding(\n",
    "                item_num, factor_num * (2 ** (num_layers - 1)))\n",
    "\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    " \n",
    "        predict_size = factor_num * 2\n",
    " \n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    " \n",
    "    def forward(self, user, item):\n",
    "        embed_user_GMF = self.embed_user_GMF(user)\n",
    "        embed_item_GMF = self.embed_item_GMF(item)\n",
    "        output_GMF = embed_user_GMF * embed_item_GMF\n",
    "\n",
    "        embed_user_MLP = self.embed_user_MLP(user)\n",
    "        embed_item_MLP = self.embed_item_MLP(item)\n",
    "        interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "        output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "\n",
    "        prediction = self.predict_layer(concat)\n",
    "        return prediction.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01: 100%|██████████| 2419/2419 [00:03<00:00, 606.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01, TRAIN LOSS: 0.5254, TRAIN ACC: 0.74%, VAL LOSS: 0.4720, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02: 100%|██████████| 2419/2419 [00:03<00:00, 644.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02, TRAIN LOSS: 0.4564, TRAIN ACC: 0.78%, VAL LOSS: 0.4608, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03: 100%|██████████| 2419/2419 [00:03<00:00, 634.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03, TRAIN LOSS: 0.4432, TRAIN ACC: 0.79%, VAL LOSS: 0.4589, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04: 100%|██████████| 2419/2419 [00:03<00:00, 624.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04, TRAIN LOSS: 0.4334, TRAIN ACC: 0.79%, VAL LOSS: 0.4630, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 05: 100%|██████████| 2419/2419 [00:03<00:00, 627.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05, TRAIN LOSS: 0.4213, TRAIN ACC: 0.80%, VAL LOSS: 0.4704, VAL ACC: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 06: 100%|██████████| 2419/2419 [00:03<00:00, 645.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06, TRAIN LOSS: 0.4055, TRAIN ACC: 0.81%, VAL LOSS: 0.4811, VAL ACC: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 07: 100%|██████████| 2419/2419 [00:03<00:00, 648.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07, TRAIN LOSS: 0.3858, TRAIN ACC: 0.82%, VAL LOSS: 0.5008, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 08: 100%|██████████| 2419/2419 [00:03<00:00, 646.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08, TRAIN LOSS: 0.3630, TRAIN ACC: 0.83%, VAL LOSS: 0.5322, VAL ACC: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 09: 100%|██████████| 2419/2419 [00:03<00:00, 645.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09, TRAIN LOSS: 0.3376, TRAIN ACC: 0.85%, VAL LOSS: 0.5649, VAL ACC: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 10: 100%|██████████| 2419/2419 [00:03<00:00, 647.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10, TRAIN LOSS: 0.3105, TRAIN ACC: 0.86%, VAL LOSS: 0.6147, VAL ACC: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 11: 100%|██████████| 2419/2419 [00:03<00:00, 626.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11, TRAIN LOSS: 0.2828, TRAIN ACC: 0.88%, VAL LOSS: 0.6776, VAL ACC: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 12: 100%|██████████| 2419/2419 [00:03<00:00, 648.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12, TRAIN LOSS: 0.2555, TRAIN ACC: 0.89%, VAL LOSS: 0.7275, VAL ACC: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 13: 100%|██████████| 2419/2419 [00:03<00:00, 642.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13, TRAIN LOSS: 0.2286, TRAIN ACC: 0.90%, VAL LOSS: 0.8059, VAL ACC: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 14: 100%|██████████| 2419/2419 [00:03<00:00, 642.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14, TRAIN LOSS: 0.2028, TRAIN ACC: 0.92%, VAL LOSS: 0.8786, VAL ACC: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 15: 100%|██████████| 2419/2419 [00:03<00:00, 641.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, TRAIN LOSS: 0.1786, TRAIN ACC: 0.93%, VAL LOSS: 0.9851, VAL ACC: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 16: 100%|██████████| 2419/2419 [00:03<00:00, 644.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16, TRAIN LOSS: 0.1564, TRAIN ACC: 0.94%, VAL LOSS: 1.1036, VAL ACC: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 17: 100%|██████████| 2419/2419 [00:03<00:00, 647.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17, TRAIN LOSS: 0.1363, TRAIN ACC: 0.95%, VAL LOSS: 1.2281, VAL ACC: 0.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 18: 100%|██████████| 2419/2419 [00:03<00:00, 609.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18, TRAIN LOSS: 0.1180, TRAIN ACC: 0.95%, VAL LOSS: 1.3646, VAL ACC: 0.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 19: 100%|██████████| 2419/2419 [00:03<00:00, 650.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19, TRAIN LOSS: 0.1016, TRAIN ACC: 0.96%, VAL LOSS: 1.5085, VAL ACC: 0.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 20: 100%|██████████| 2419/2419 [00:03<00:00, 649.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, TRAIN LOSS: 0.0876, TRAIN ACC: 0.97%, VAL LOSS: 1.6436, VAL ACC: 0.72%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = ReviewDataset(X_train, Y_train, user_encoder, item_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = ReviewDataset(X_val, Y_val, user_encoder, item_encoder)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = NCF(user_num=len(user_encoder.classes_), item_num=len(item_encoder.classes_)).to(device)\n",
    "fn_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def fn_acc(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    시그모이드를 적용한 예측값과 실제값으로 정확도를 계산합니다.\n",
    "    \"\"\"\n",
    "    predictions = (torch.sigmoid(y_pred) >= 0.5).float()\n",
    "    correct = (predictions == y_true).float().sum()\n",
    "    return correct / len(y_true)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total_train_samples = 0\n",
    "    for user, item, y in tqdm(train_loader, desc=f\"EPOCH: {epoch+1:02d}\"):\n",
    "        user, item, y = user.to(device), item.to(device), y.to(device)\n",
    "        y_hat = model(user, item)\n",
    "        loss = fn_loss(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = y.size(0)\n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_acc += fn_acc(y_hat, y) * batch_size\n",
    "        total_train_samples += batch_size\n",
    "        \n",
    "    train_loss /= total_train_samples\n",
    "    train_acc = (train_acc / total_train_samples)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, y in val_loader:\n",
    "            user, item, y = user.to(device), item.to(device), y.to(device)\n",
    "            y_hat = model(user, item)\n",
    "            loss = fn_loss(y_hat, y)\n",
    "            \n",
    "            batch_size = y.size(0)\n",
    "            val_loss += loss.item() * batch_size\n",
    "            val_acc += fn_acc(y_hat, y) * batch_size\n",
    "            total_val_samples += batch_size\n",
    "        \n",
    "    val_loss /= total_val_samples\n",
    "    val_acc = (val_acc / total_val_samples)\n",
    "    \n",
    "    print(f\"EPOCH: {epoch+1:02d}, \"\n",
    "          f\"TRAIN LOSS: {train_loss:.4f}, TRAIN ACC: {train_acc:.2f}, \"\n",
    "          f\"VAL LOSS: {val_loss:.4f}, VAL ACC: {val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 생성 중...\n",
      "테스트 데이터 수: 91742\n",
      "모델 평가 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 359/359 [00:00<00:00, 808.38batch/s, loss=2.7553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "모델 평가 결과\n",
      "==================================================\n",
      "Loss: 1.6484\n",
      "Accuracy: 0.7224\n",
      "Precision: 0.7938\n",
      "Recall: 0.7919\n",
      "F1 Score: 0.7929\n",
      "AUC-ROC: 0.7671\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    모델을 평가하고 다양한 평가 지표를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    model: 학습된 모델\n",
    "    test_loader: 테스트 데이터 로더\n",
    "    device: 연산 장치 (CPU/GPU)\n",
    "    \n",
    "    Returns:\n",
    "    dict: 다양한 평가 지표를 포함한 딕셔너리\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 예측값과 실제값을 저장할 리스트\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_targets = []\n",
    "    total_loss = 0\n",
    "    fn_loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # tqdm으로 진행상황 표시\n",
    "    test_progress = tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, y in test_progress:\n",
    "            # 데이터를 device로 이동\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            y_hat = model(user, item)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = fn_loss(y_hat, y)\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            \n",
    "            # 시그모이드 함수를 통한 확률값 계산\n",
    "            probabilities = torch.sigmoid(y_hat)\n",
    "            \n",
    "            # 예측 클래스 결정 (0.5를 임계값으로 사용)\n",
    "            predictions = (probabilities >= 0.5).float()\n",
    "            \n",
    "            # CPU로 이동하고 numpy 배열로 변환\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            \n",
    "            # 진행바 업데이트\n",
    "            test_progress.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # numpy 배열로 변환\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # 평균 손실 계산\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # 각종 평가 지표 계산\n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy_score(all_targets, all_predictions),\n",
    "        'precision': precision_score(all_targets, all_predictions),\n",
    "        'recall': recall_score(all_targets, all_predictions),\n",
    "        'f1': f1_score(all_targets, all_predictions),\n",
    "        'auc_roc': roc_auc_score(all_targets, all_probabilities)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 평가 실행\n",
    "def print_evaluation_results(metrics):\n",
    "    \"\"\"\n",
    "    평가 결과를 보기 좋게 출력합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"모델 평가 결과\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# 테스트 데이터셋 생성 및 평가 실행\n",
    "def evaluate_test_set(X_test, Y_test, model, user_encoder, item_encoder, batch_size=256):\n",
    "    \"\"\"\n",
    "    테스트 데이터셋을 생성하고 모델을 평가합니다.\n",
    "    \"\"\"\n",
    "    print(\"테스트 데이터셋 생성 중...\")\n",
    "    test_dataset = ReviewDataset(X_test, Y_test, user_encoder, item_encoder)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False  # 테스트 시에는 모든 샘플을 평가\n",
    "    )\n",
    "    \n",
    "    print(f\"테스트 데이터 수: {len(test_dataset)}\")\n",
    "    print(\"모델 평가 중...\")\n",
    "    \n",
    "    # 평가 실행\n",
    "    device = next(model.parameters()).device  # 모델이 있는 디바이스 확인\n",
    "    metrics = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print_evaluation_results(metrics)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_test_set(\n",
    "    X_test=X_test,\n",
    "    Y_test=Y_test,\n",
    "    model=model,\n",
    "    user_encoder=user_encoder,\n",
    "    item_encoder=item_encoder,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-modeling-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
