{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/visuworks/.cache/kagglehub/datasets/andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews/versions/4\n",
      "(143258, 16)\n",
      "(1444963, 11)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews\")\n",
    "path = path.replace('\\\\', '/')\n",
    "\n",
    "movie_df = pd.read_csv(os.path.join(path, os.listdir(path)[0]))\n",
    "review_df = pd.read_csv(os.path.join(path, os.listdir(path)[1]))\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(movie_df.shape)\n",
    "print(review_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of filtered_movie_ids: 7002\n",
      "# of filtered_review_ids: 7933\n"
     ]
    }
   ],
   "source": [
    "# 영화는 리뷰 개수가 상위 10%인 영화만 사용, 56개 이상\n",
    "tmp = review_df['id'].value_counts() >= 56\n",
    "filtered_movie_ids = tmp[tmp].index.tolist()\n",
    "\n",
    "# 사용자는 작성한 리뷰가 4개 이상인 사용자만 사용\n",
    "tmp = review_df['criticName'].value_counts() >= 4\n",
    "filtered_review_ids = tmp[tmp].index.tolist()\n",
    "\n",
    "print(f\"# of filtered_movie_ids: {len(filtered_movie_ids)}\")\n",
    "print(f\"# of filtered_review_ids: {len(filtered_review_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_movie_ids를 set으로 변환하여 검색 속도 최적화\n",
    "filtered_movie_ids = set(filtered_movie_ids)\n",
    "filtered_review_ids = set(filtered_review_ids)\n",
    "\n",
    "filtered_review_df = review_df[review_df['id'].apply(lambda x: x in filtered_movie_ids)].reset_index(drop=True)\n",
    "filtered_review_df = filtered_review_df[filtered_review_df['criticName'].apply(lambda x: x in filtered_review_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_filtered_df():\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews\")\n",
    "    path = path.replace('\\\\', '/')\n",
    "\n",
    "    movie_df = pd.read_csv(os.path.join(path, os.listdir(path)[0]))\n",
    "    review_df = pd.read_csv(os.path.join(path, os.listdir(path)[1]))\n",
    "    \n",
    "    # 영화는 리뷰 개수가 상위 10%인 영화만 사용, 56개 이상\n",
    "    tmp = review_df['id'].value_counts() >= 56\n",
    "    filtered_movie_ids = tmp[tmp].index.tolist()\n",
    "\n",
    "    # 사용자는 작성한 리뷰가 4개 이상인 사용자만 사용\n",
    "    tmp = review_df['criticName'].value_counts() >= 4\n",
    "    filtered_review_ids = tmp[tmp].index.tolist()\n",
    "    \n",
    "    # filtered_movie_ids를 set으로 변환하여 검색 속도 최적화\n",
    "    filtered_movie_ids = set(filtered_movie_ids)\n",
    "    filtered_review_ids = set(filtered_review_ids)\n",
    "\n",
    "    filtered_review_df = review_df[review_df['id'].apply(lambda x: x in filtered_movie_ids)].reset_index(drop=True)\n",
    "    filtered_review_df = filtered_review_df[filtered_review_df['criticName'].apply(lambda x: x in filtered_review_ids)].reset_index(drop=True)\n",
    "    \n",
    "    scoreSentiment_map = {\"POSITIVE\": 1, \"NEGATIVE\": 0}\n",
    "\n",
    "    # map 메서드 사용\n",
    "    filtered_review_df['scoreSentiment'] = filtered_review_df['scoreSentiment'].map(scoreSentiment_map)\n",
    "\n",
    "    return filtered_review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      "(555578, 11)\n",
      "\n",
      "Validation DataFrame:\n",
      "(275831, 11)\n",
      "\n",
      "Test DataFrame:\n",
      "(99686, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def split_data(df, user_col, item_col, train_ratio=0.6, val_ratio=0.3, test_ratio=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into train, validation, and test sets by a 6:3:1 ratio.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing user and item interactions.\n",
    "    - user_col (str): The column name representing user IDs.\n",
    "    - item_col (str): The column name representing item (movie) IDs.\n",
    "    - train_ratio (float): Proportion of the dataset to include in the train split.\n",
    "    - val_ratio (float): Proportion of the dataset to include in the validation split.\n",
    "    - test_ratio (float): Proportion of the dataset to include in the test split.\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): Training data.\n",
    "    - val_df (pd.DataFrame): Validation data.\n",
    "    - test_df (pd.DataFrame): Testing data.\n",
    "    \"\"\"\n",
    "    # Ensure the ratios add up to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum up to 1.\"\n",
    "\n",
    "    train_list, val_list, test_list = [], [], []\n",
    "\n",
    "    # Group by user to split data per user\n",
    "    for user, group in df.groupby(user_col):\n",
    "        # Shuffle the group\n",
    "        group = group.sample(frac=1, random_state=random_state)\n",
    "        n = len(group)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        train_end = int(n * train_ratio)\n",
    "        val_end = train_end + int(n * val_ratio)\n",
    "        \n",
    "        # Split data\n",
    "        train_data = group.iloc[:train_end]\n",
    "        val_data = group.iloc[train_end:val_end]\n",
    "        test_data = group.iloc[val_end:]\n",
    "\n",
    "        # Append to respective lists\n",
    "        train_list.append(train_data)\n",
    "        val_list.append(val_data)\n",
    "        test_list.append(test_data)\n",
    "\n",
    "    # Concatenate all splits\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    val_df = pd.concat(val_list).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "filtered_review_df = get_filtered_df()\n",
    "train_df, val_df, test_df = split_data(filtered_review_df, user_col='criticName', item_col='id')\n",
    "\n",
    "print(\"Train DataFrame:\")\n",
    "print(train_df.shape)\n",
    "print(\"\\nValidation DataFrame:\")\n",
    "print(val_df.shape)\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 빌드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"criticName\"\n",
    "item_col = \"id\"\n",
    "label_col = \"scoreSentiment\"\n",
    "df = filtered_review_df\n",
    "\n",
    "num_movie_features = 64\n",
    "num_review_features = 64\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# Create two node types \"paper\" and \"author\" holding a feature matrix:\n",
    "data['movie'].x = torch.randn(df[item_col].nunique(), num_movie_features)\n",
    "data['reviewer'].x = torch.randn(df[user_col].nunique(), num_review_features)\n",
    "\n",
    "# Create an edge type \"(author, writes, paper)\" and building the\n",
    "# graph connectivity:\n",
    "# Map user and item IDs to unique indices for graph processing\n",
    "unique_users = df[user_col].unique()\n",
    "unique_items = df[item_col].unique()\n",
    "\n",
    "user_map = {user: idx for idx, user in enumerate(unique_users)}\n",
    "item_map = {item: idx + len(unique_users) for idx, item in enumerate(unique_items)}\n",
    "\n",
    "# Convert edges to indices\n",
    "edge_index = []\n",
    "user_indices = df[user_col].map(user_map).values\n",
    "item_indices = df[item_col].map(item_map).values\n",
    "edge_index.append(torch.tensor([user_indices, item_indices], dtype=torch.long))\n",
    "    \n",
    "edge_index = torch.cat(edge_index, dim=1)  # Combine edges from train, val, test\n",
    "data['movie', 'rates', 'reviewer'].edge_index = edge_index  # [2, num_edges]\n",
    "data['movie', 'rates', 'reviewer'].rating = torch.tensor(df[label_col])  # float 타입\n",
    "\n",
    "data['reviewer', 'rates', 'movie'].edge_index = data['movie', 'rates', 'reviewer'].edge_index[[1, 0]]\n",
    "data['reviewer', 'rates', 'movie'].rating = torch.tensor(df[label_col])  # float 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[7002, 64] },\n",
       "  reviewer={ x=[7494, 64] },\n",
       "  (movie, rates, reviewer)={\n",
       "    edge_index=[2, 931095],\n",
       "    rating=[931095],\n",
       "  },\n",
       "  (reviewer, rates, movie)={\n",
       "    edge_index=[2, 931095],\n",
       "    rating=[931095],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = []\n",
    "tr_user_indices = train_df[user_col].map(user_map).values\n",
    "tr_item_indices = train_df[item_col].map(item_map).values\n",
    "edge_index.append(torch.tensor([tr_user_indices, tr_item_indices], dtype=torch.long))\n",
    "tr_edge_index = torch.cat(edge_index, dim=1)  # Combine edges from train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,  ...,  5513,  1273,   115],\n",
       "        [ 7494,  7494,  7494,  ..., 14495, 14495, 14495]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie', 'rates', 'reviewer'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5870), tensor(9546))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_edge_index[0][0], tr_edge_index[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "# HeteroGraphSAGE 정의\n",
    "class HeteroGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super(HeteroGraphSAGE, self).__init__()\n",
    "        # 첫 번째 HeteroConv 레이어 정의\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('movie', 'rates', 'reviewer'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('reviewer', 'rates', 'movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # 두 번째 HeteroConv 레이어 정의\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('movie', 'rates', 'reviewer'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('reviewer', 'rates', 'movie'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # 최종 분류 레이어 (이진 분류)\n",
    "        self.fc = Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # 첫 번째 GraphSAGE 레이어\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # 두 번째 GraphSAGE 레이어\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "\n",
    "        # 엣지 표현 계산 (user -> item)\n",
    "        user_item_edge_index = edge_index_dict[('movie', 'rates', 'reviewer')]\n",
    "        user_repr = x_dict['movie'][user_item_edge_index[0]]\n",
    "        item_repr = x_dict['reviewer'][user_item_edge_index[1]]\n",
    "\n",
    "        # 엣지별 예측값 계산\n",
    "        edge_repr = user_repr + item_repr\n",
    "        edge_prediction = torch.sigmoid(self.fc(edge_repr).squeeze(-1))  # Sigmoid for binary classification\n",
    "\n",
    "        return edge_prediction\n",
    "    \n",
    "    \n",
    "model = HeteroGraphSAGE(\n",
    "        metadata=data.metadata(),  # HeteroData의 메타데이터 사용\n",
    "        hidden_channels=128,\n",
    "        out_channels=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[7002, 64] },\n",
       "  reviewer={ x=[7494, 64] },\n",
       "  (movie, rates, reviewer)={\n",
       "    edge_index=[2, 931095],\n",
       "    rating=[931095],\n",
       "  },\n",
       "  (reviewer, rates, movie)={\n",
       "    edge_index=[2, 931095],\n",
       "    rating=[931095],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGraphSAGE(\n",
       "  (conv1): HeteroConv(num_relations=2)\n",
       "  (conv2): HeteroConv(num_relations=2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 추출\n",
    "x_dict = data.x_dict\n",
    "edge_index_dict = data.edge_index_dict\n",
    "rating = data['movie', 'rates', 'reviewer'].rating.float().to(device)\n",
    "pred = model(x_dict, edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([931095])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "rating = data['movie', 'rates', 'reviewer'].rating\n",
    "\n",
    "train_edge_index = torch.arange(int(0.6 * len(rating)))\n",
    "val_edge_index = torch.arange(int(0.6 * len(rating)), int(0.9 * len(rating)))\n",
    "test_edge_index = torch.arange(int(0.9 * len(rating)), len(rating))\n",
    "\n",
    "train_labels = data['movie', 'rates', 'reviewer'].rating[train_edge_index].float().to(device)\n",
    "val_labels = data['movie', 'rates', 'reviewer'].rating[val_edge_index].float().to(device)\n",
    "test_labels = data['movie', 'rates', 'reviewer'].rating[test_edge_index].float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6416, Train Acc: 0.6678, Val Loss: 0.6600, Val Acc: 0.6666\n",
      "Epoch 2/100, Train Loss: 0.6356, Train Acc: 0.6676, Val Loss: 0.6369, Val Acc: 0.6656\n",
      "Epoch 3/100, Train Loss: 0.7291, Train Acc: 0.6678, Val Loss: 0.7613, Val Acc: 0.6666\n",
      "Epoch 4/100, Train Loss: 0.6475, Train Acc: 0.6634, Val Loss: 0.6767, Val Acc: 0.6621\n",
      "Epoch 5/100, Train Loss: 1.0054, Train Acc: 0.3322, Val Loss: 1.0037, Val Acc: 0.3334\n",
      "Epoch 6/100, Train Loss: 0.6674, Train Acc: 0.6395, Val Loss: 0.6861, Val Acc: 0.6394\n",
      "Epoch 7/100, Train Loss: 0.6370, Train Acc: 0.6689, Val Loss: 0.6562, Val Acc: 0.6677\n",
      "Epoch 8/100, Train Loss: 0.6644, Train Acc: 0.6396, Val Loss: 0.6647, Val Acc: 0.6386\n",
      "Epoch 9/100, Train Loss: 0.6683, Train Acc: 0.6678, Val Loss: 0.6882, Val Acc: 0.6666\n",
      "Epoch 10/100, Train Loss: 0.6753, Train Acc: 0.6678, Val Loss: 0.6921, Val Acc: 0.6666\n",
      "Epoch 11/100, Train Loss: 0.6304, Train Acc: 0.6676, Val Loss: 0.6314, Val Acc: 0.6656\n",
      "Epoch 12/100, Train Loss: 0.6404, Train Acc: 0.6678, Val Loss: 0.6464, Val Acc: 0.6666\n",
      "Epoch 13/100, Train Loss: 0.6289, Train Acc: 0.6677, Val Loss: 0.6300, Val Acc: 0.6661\n",
      "Epoch 14/100, Train Loss: 0.6281, Train Acc: 0.6676, Val Loss: 0.6291, Val Acc: 0.6656\n",
      "Epoch 15/100, Train Loss: 0.6530, Train Acc: 0.6659, Val Loss: 0.6651, Val Acc: 0.6641\n",
      "Epoch 16/100, Train Loss: 0.6555, Train Acc: 0.6642, Val Loss: 0.6696, Val Acc: 0.6624\n",
      "Epoch 17/100, Train Loss: 0.6290, Train Acc: 0.6676, Val Loss: 0.6303, Val Acc: 0.6656\n",
      "Epoch 18/100, Train Loss: 0.6343, Train Acc: 0.6691, Val Loss: 0.6463, Val Acc: 0.6672\n",
      "Epoch 19/100, Train Loss: 0.6299, Train Acc: 0.6686, Val Loss: 0.6398, Val Acc: 0.6668\n",
      "Epoch 20/100, Train Loss: 0.6439, Train Acc: 0.6676, Val Loss: 0.6456, Val Acc: 0.6656\n",
      "Epoch 21/100, Train Loss: 0.6326, Train Acc: 0.6676, Val Loss: 0.6384, Val Acc: 0.6656\n",
      "Epoch 22/100, Train Loss: 0.6305, Train Acc: 0.6676, Val Loss: 0.6352, Val Acc: 0.6656\n",
      "Epoch 23/100, Train Loss: 0.6315, Train Acc: 0.6676, Val Loss: 0.6329, Val Acc: 0.6656\n",
      "Epoch 24/100, Train Loss: 0.6253, Train Acc: 0.6686, Val Loss: 0.6294, Val Acc: 0.6668\n",
      "Epoch 25/100, Train Loss: 0.6255, Train Acc: 0.6686, Val Loss: 0.6291, Val Acc: 0.6668\n",
      "Epoch 26/100, Train Loss: 0.6244, Train Acc: 0.6676, Val Loss: 0.6255, Val Acc: 0.6656\n",
      "Epoch 27/100, Train Loss: 0.6263, Train Acc: 0.6686, Val Loss: 0.6281, Val Acc: 0.6668\n",
      "Epoch 28/100, Train Loss: 0.6251, Train Acc: 0.6678, Val Loss: 0.6260, Val Acc: 0.6665\n",
      "Epoch 29/100, Train Loss: 0.6255, Train Acc: 0.6686, Val Loss: 0.6264, Val Acc: 0.6668\n",
      "Epoch 30/100, Train Loss: 0.6244, Train Acc: 0.6678, Val Loss: 0.6265, Val Acc: 0.6666\n",
      "Epoch 31/100, Train Loss: 0.6252, Train Acc: 0.6678, Val Loss: 0.6294, Val Acc: 0.6666\n",
      "Epoch 32/100, Train Loss: 0.6241, Train Acc: 0.6686, Val Loss: 0.6251, Val Acc: 0.6668\n",
      "Epoch 33/100, Train Loss: 0.6259, Train Acc: 0.6678, Val Loss: 0.6312, Val Acc: 0.6666\n",
      "Epoch 34/100, Train Loss: 0.6249, Train Acc: 0.6678, Val Loss: 0.6292, Val Acc: 0.6666\n",
      "Epoch 35/100, Train Loss: 0.6229, Train Acc: 0.6692, Val Loss: 0.6240, Val Acc: 0.6673\n",
      "Epoch 36/100, Train Loss: 0.6221, Train Acc: 0.6689, Val Loss: 0.6235, Val Acc: 0.6677\n",
      "Epoch 37/100, Train Loss: 0.6216, Train Acc: 0.6695, Val Loss: 0.6227, Val Acc: 0.6682\n",
      "Epoch 38/100, Train Loss: 0.6213, Train Acc: 0.6692, Val Loss: 0.6226, Val Acc: 0.6673\n",
      "Epoch 39/100, Train Loss: 0.6219, Train Acc: 0.6696, Val Loss: 0.6245, Val Acc: 0.6676\n",
      "Epoch 40/100, Train Loss: 0.6213, Train Acc: 0.6696, Val Loss: 0.6243, Val Acc: 0.6676\n",
      "Epoch 41/100, Train Loss: 0.6208, Train Acc: 0.6692, Val Loss: 0.6222, Val Acc: 0.6673\n",
      "Epoch 42/100, Train Loss: 0.6206, Train Acc: 0.6696, Val Loss: 0.6232, Val Acc: 0.6676\n",
      "Epoch 43/100, Train Loss: 0.6206, Train Acc: 0.6696, Val Loss: 0.6231, Val Acc: 0.6676\n",
      "Epoch 44/100, Train Loss: 0.6213, Train Acc: 0.6692, Val Loss: 0.6228, Val Acc: 0.6673\n",
      "Epoch 45/100, Train Loss: 0.6199, Train Acc: 0.6699, Val Loss: 0.6224, Val Acc: 0.6680\n",
      "Epoch 46/100, Train Loss: 0.6195, Train Acc: 0.6699, Val Loss: 0.6220, Val Acc: 0.6680\n",
      "Epoch 47/100, Train Loss: 0.6192, Train Acc: 0.6696, Val Loss: 0.6206, Val Acc: 0.6676\n",
      "Epoch 48/100, Train Loss: 0.6194, Train Acc: 0.6702, Val Loss: 0.6216, Val Acc: 0.6682\n",
      "Epoch 49/100, Train Loss: 0.6191, Train Acc: 0.6702, Val Loss: 0.6208, Val Acc: 0.6682\n",
      "Epoch 50/100, Train Loss: 0.6187, Train Acc: 0.6702, Val Loss: 0.6200, Val Acc: 0.6682\n",
      "Epoch 51/100, Train Loss: 0.6187, Train Acc: 0.6699, Val Loss: 0.6200, Val Acc: 0.6685\n",
      "Epoch 52/100, Train Loss: 0.6187, Train Acc: 0.6699, Val Loss: 0.6201, Val Acc: 0.6685\n",
      "Epoch 53/100, Train Loss: 0.6182, Train Acc: 0.6702, Val Loss: 0.6195, Val Acc: 0.6684\n",
      "Epoch 54/100, Train Loss: 0.6182, Train Acc: 0.6699, Val Loss: 0.6196, Val Acc: 0.6685\n",
      "Epoch 55/100, Train Loss: 0.6178, Train Acc: 0.6702, Val Loss: 0.6191, Val Acc: 0.6689\n",
      "Epoch 56/100, Train Loss: 0.6175, Train Acc: 0.6711, Val Loss: 0.6190, Val Acc: 0.6695\n",
      "Epoch 57/100, Train Loss: 0.6175, Train Acc: 0.6715, Val Loss: 0.6192, Val Acc: 0.6700\n",
      "Epoch 58/100, Train Loss: 0.6172, Train Acc: 0.6715, Val Loss: 0.6191, Val Acc: 0.6700\n",
      "Epoch 59/100, Train Loss: 0.6169, Train Acc: 0.6710, Val Loss: 0.6184, Val Acc: 0.6694\n",
      "Epoch 60/100, Train Loss: 0.6167, Train Acc: 0.6710, Val Loss: 0.6184, Val Acc: 0.6694\n",
      "Epoch 61/100, Train Loss: 0.6166, Train Acc: 0.6712, Val Loss: 0.6182, Val Acc: 0.6696\n",
      "Epoch 62/100, Train Loss: 0.6164, Train Acc: 0.6714, Val Loss: 0.6179, Val Acc: 0.6699\n",
      "Epoch 63/100, Train Loss: 0.6161, Train Acc: 0.6717, Val Loss: 0.6178, Val Acc: 0.6704\n",
      "Epoch 64/100, Train Loss: 0.6159, Train Acc: 0.6719, Val Loss: 0.6175, Val Acc: 0.6705\n",
      "Epoch 65/100, Train Loss: 0.6157, Train Acc: 0.6720, Val Loss: 0.6172, Val Acc: 0.6706\n",
      "Epoch 66/100, Train Loss: 0.6155, Train Acc: 0.6723, Val Loss: 0.6169, Val Acc: 0.6712\n",
      "Epoch 67/100, Train Loss: 0.6153, Train Acc: 0.6726, Val Loss: 0.6167, Val Acc: 0.6718\n",
      "Epoch 68/100, Train Loss: 0.6151, Train Acc: 0.6725, Val Loss: 0.6166, Val Acc: 0.6711\n",
      "Epoch 69/100, Train Loss: 0.6149, Train Acc: 0.6725, Val Loss: 0.6164, Val Acc: 0.6718\n",
      "Epoch 70/100, Train Loss: 0.6147, Train Acc: 0.6727, Val Loss: 0.6162, Val Acc: 0.6720\n",
      "Epoch 71/100, Train Loss: 0.6144, Train Acc: 0.6732, Val Loss: 0.6161, Val Acc: 0.6715\n",
      "Epoch 72/100, Train Loss: 0.6142, Train Acc: 0.6733, Val Loss: 0.6159, Val Acc: 0.6716\n",
      "Epoch 73/100, Train Loss: 0.6140, Train Acc: 0.6732, Val Loss: 0.6158, Val Acc: 0.6716\n",
      "Epoch 74/100, Train Loss: 0.6138, Train Acc: 0.6733, Val Loss: 0.6155, Val Acc: 0.6716\n",
      "Epoch 75/100, Train Loss: 0.6136, Train Acc: 0.6734, Val Loss: 0.6153, Val Acc: 0.6721\n",
      "Epoch 76/100, Train Loss: 0.6134, Train Acc: 0.6736, Val Loss: 0.6151, Val Acc: 0.6723\n",
      "Epoch 77/100, Train Loss: 0.6132, Train Acc: 0.6733, Val Loss: 0.6149, Val Acc: 0.6717\n",
      "Epoch 78/100, Train Loss: 0.6130, Train Acc: 0.6736, Val Loss: 0.6147, Val Acc: 0.6721\n",
      "Epoch 79/100, Train Loss: 0.6128, Train Acc: 0.6738, Val Loss: 0.6145, Val Acc: 0.6727\n",
      "Epoch 80/100, Train Loss: 0.6126, Train Acc: 0.6738, Val Loss: 0.6144, Val Acc: 0.6723\n",
      "Epoch 81/100, Train Loss: 0.6124, Train Acc: 0.6740, Val Loss: 0.6141, Val Acc: 0.6732\n",
      "Epoch 82/100, Train Loss: 0.6122, Train Acc: 0.6740, Val Loss: 0.6139, Val Acc: 0.6732\n",
      "Epoch 83/100, Train Loss: 0.6121, Train Acc: 0.6739, Val Loss: 0.6139, Val Acc: 0.6724\n",
      "Epoch 84/100, Train Loss: 0.6118, Train Acc: 0.6741, Val Loss: 0.6137, Val Acc: 0.6730\n",
      "Epoch 85/100, Train Loss: 0.6117, Train Acc: 0.6740, Val Loss: 0.6135, Val Acc: 0.6729\n",
      "Epoch 86/100, Train Loss: 0.6115, Train Acc: 0.6741, Val Loss: 0.6134, Val Acc: 0.6727\n",
      "Epoch 87/100, Train Loss: 0.6113, Train Acc: 0.6742, Val Loss: 0.6132, Val Acc: 0.6732\n",
      "Epoch 88/100, Train Loss: 0.6111, Train Acc: 0.6744, Val Loss: 0.6130, Val Acc: 0.6734\n",
      "Epoch 89/100, Train Loss: 0.6110, Train Acc: 0.6744, Val Loss: 0.6130, Val Acc: 0.6731\n",
      "Epoch 90/100, Train Loss: 0.6108, Train Acc: 0.6745, Val Loss: 0.6128, Val Acc: 0.6733\n",
      "Epoch 91/100, Train Loss: 0.6106, Train Acc: 0.6746, Val Loss: 0.6126, Val Acc: 0.6737\n",
      "Epoch 92/100, Train Loss: 0.6104, Train Acc: 0.6745, Val Loss: 0.6125, Val Acc: 0.6733\n",
      "Epoch 93/100, Train Loss: 0.6103, Train Acc: 0.6746, Val Loss: 0.6124, Val Acc: 0.6739\n",
      "Epoch 94/100, Train Loss: 0.6101, Train Acc: 0.6749, Val Loss: 0.6121, Val Acc: 0.6742\n",
      "Epoch 95/100, Train Loss: 0.6101, Train Acc: 0.6749, Val Loss: 0.6123, Val Acc: 0.6735\n",
      "Epoch 96/100, Train Loss: 0.6098, Train Acc: 0.6751, Val Loss: 0.6119, Val Acc: 0.6743\n",
      "Epoch 97/100, Train Loss: 0.6097, Train Acc: 0.6750, Val Loss: 0.6118, Val Acc: 0.6742\n",
      "Epoch 98/100, Train Loss: 0.6095, Train Acc: 0.6749, Val Loss: 0.6118, Val Acc: 0.6737\n",
      "Epoch 99/100, Train Loss: 0.6093, Train Acc: 0.6752, Val Loss: 0.6116, Val Acc: 0.6743\n",
      "Epoch 100/100, Train Loss: 0.6092, Train Acc: 0.6753, Val Loss: 0.6114, Val Acc: 0.6744\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = HeteroGraphSAGE(\n",
    "        metadata=data.metadata(),  # HeteroData의 메타데이터 사용\n",
    "        hidden_channels=128,\n",
    "        out_channels=64\n",
    "    ).to(device)\n",
    "\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    pred = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # Train loss 계산\n",
    "    train_pred = pred[train_edge_index]\n",
    "    loss = loss_fn(train_pred, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation loss 계산\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = pred[val_edge_index]\n",
    "        val_loss = loss_fn(val_pred, val_labels)\n",
    "\n",
    "    # Accuracy 계산\n",
    "    train_acc = ((train_pred > 0.5).float() == train_labels).float().mean().item()\n",
    "    val_acc = ((val_pred > 0.5).float() == val_labels).float().mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6585\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = data.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    pred = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # 테스트 정확도 계산\n",
    "    test_pred = pred[test_edge_index]\n",
    "    test_acc = ((test_pred > 0.5).float() == test_labels).float().mean().item()\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
